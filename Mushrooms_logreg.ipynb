{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb271648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for the project\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from scipy import optimize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531b116a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10010000001000000100001000000010100101000010000000010001000010001000100000000100000010001000001000100000000100</th>\n",
       "      <th>00010000001000000000101000100000100110000010000000011000000010001000100000000100000010001000001000000100000010</th>\n",
       "      <th>00000010001000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000010</th>\n",
       "      <th>10010000010000010000001000000010100101000000001000010001000010001000100000000100000010001000001000100000000100</th>\n",
       "      <th>00010000001010000000010000000100101010000010000000100001000010001000100000000100000010001001000000000100010000</th>\n",
       "      <th>00010000010000000000101000100000100110000000001000011000000010001000100000000100000010001000001000100000000010</th>\n",
       "      <th>00000010001000010000001000100000100110100000000000011000000010001000100000000100000010001000001000100000000010</th>\n",
       "      <th>00000010010000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000100</th>\n",
       "      <th>10010000010000010000001000000010100101000000000010010001000010001000100000000100000010001000001000100000001000</th>\n",
       "      <th>00000010001000000000101000100000100110100000000000011000000010001000100000000100000010001000001000100000000100</th>\n",
       "      <th>...</th>\n",
       "      <th>00010000001000000100010000000100010110000000000001010010000010001001000000001000000001001000001010000000001000</th>\n",
       "      <th>10001000010000000100010000001000100101000000000100100010000010100000000010000100000010001001000000010000001000.2</th>\n",
       "      <th>10001000001000001000010000000001100101000000000100100010001000001000000010000100000010001001000000010000001000.2</th>\n",
       "      <th>10001000010000000100010100000000100101000000000100100010001000001000000010000100000010001001000000010000001000.2</th>\n",
       "      <th>00001000001000000100010000000100010110000000000001010010000010001001000000001000000001001000001000000010100000</th>\n",
       "      <th>00010000001000000100010000000100010110000000000001010010000010001001000000001000000000101000001000000010001000</th>\n",
       "      <th>01000000001000000100010000000100010110000000001000010010000010001001000000001000000001001000001000000010100000</th>\n",
       "      <th>10001000010000000100010000000001100101000000000100100010000010100000100000000100000010001001000000010000001000.2</th>\n",
       "      <th>00010000001000000100010000000100010110000000000001010010000010001001000000001000000001001000001010000000100000</th>\n",
       "      <th>Unnamed: 8124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 8125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [10010000001000000100001000000010100101000010000000010001000010001000100000000100000010001000001000100000000100, 00010000001000000000101000100000100110000010000000011000000010001000100000000100000010001000001000000100000010, 00000010001000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000010, 10010000010000010000001000000010100101000000001000010001000010001000100000000100000010001000001000100000000100, 00010000001010000000010000000100101010000010000000100001000010001000100000000100000010001001000000000100010000, 00010000010000000000101000100000100110000000001000011000000010001000100000000100000010001000001000100000000010, 00000010001000010000001000100000100110100000000000011000000010001000100000000100000010001000001000100000000010, 00000010010000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000100, 10010000010000010000001000000010100101000000000010010001000010001000100000000100000010001000001000100000001000, 00000010001000000000101000100000100110100000000000011000000010001000100000000100000010001000001000100000000100, 00010000010000000000101000010000100110100000000000011000000010001000100000000100000010001000001000000100000010, 00010000010000000000101000100000100110000000001000011000000010001000100000000100000010001000001000100000000100, 00000010001000000000101000100000100110000001000000011000000010001000100000000100000010001000001000000100000100, 10010000010000010000001000000010100101000010000000010001000010001000100000000100000010001000001000000100001000, 00010001000000000100010000000100101010000000001000100001000011000000100000000100000010001001000000100000010000, 00000101000010000000010000000100100101000010000000010001000010001000100000000100000010001000001000000100000001, 01000001000000010000010000000100101010000010000000100001000010001000100000000100000010001001000000000100010000, 10010000001000000100001000000010100101000000001000010001000010001000100000000100000010001000001000100000000100, 10010000010000010000001000000010100101000000001000010001000010001000100000000100000010001000001000000100000100, 10010000001000000100001000000010100101000010000000010001000010001000100000000100000010001000001000000100000100, 00000010001000000000101000100000100110000010000000011000000010001000100000000100000010001000001000000100000100, 10010000010000000100001000000010100101000000001000010001000010001000100000000100000010001000001000000100001000, 00000010010000000000101000010000100110000010000000011000000010001000100000000100000010001000001000000100000100, 00000010010000010000001000100000100110000001000000011000000010001000100000000100000010001000001000000100000010, 00000010001000010000001000010000100110100000000000011000000010001000100000000100000010001000001000100000000100, 11000000001000010000001000000010100101000000001000010001000010001000100000000100000010001000001000000100001000, 00010000010000000000101000100000100110000000001000011000000010001000100000000100000010001000001000000100000010, 00010000010000010000001000010000100110000001000000011000000010001000100000000100000010001000001000000100000010, 01000001000000000100010000000100100101000010000000010001000010001000100000000100000010001000001000100000000001, 00010000001000000000101000100000101001000000001000100000100010001000100000000100000010001000001000000100001000, 00000010001000000000101000010000100110100000000000011000000010001000100000000100000010001000001000000100000010, 10010000010000010000001000000010100101000010000000010001000010001000100000000100000010001000001000000100000100, 00010000010000000000101000010000100110000000001000011000000010001000100000000100000010001000001000000100000010, 00010000010000000100001000010000100110000000000010010100000010010000100000000100000010001000001000000100000001, 00000010010000000000101000010000100110000000001000011000000010001000100000000100000010001000001000000100000100, 00010001000000000000101000010000101001000001000000100000100010001000100000000100000010001000001000000100001000, 00000101000010000000010000000100100101000010000000010001000010001000100000000100000010001000001000100000001000, 10010000010000000100001000000010100101000001000000010001000010001000100000000100000010001000001000000100000100, 00010001000000000000101000100000101001000000000010100000100010001000100000000100000010001000001000000100001000, 00000010001000000000101000010000100110000010000000011000000010001000100000000100000010001000001000100000000100, 00000010010000000000101000100000100110000000001000011000000010001000100000000100000010001000001000000100000100, 00010000010000000000101000010000100110000000001000010100000010010000100000000100000010001000001000100000000001, 00010001000000000100010000000100100101100000000000010001000010001000100000000100000010001000001000100000000001, 10010000010000010000001000000010100101000000000010010001000010001000100000000100000010001000001000000100001000, 00010000001000000000101000100000100110000001000000011000000010001000100000000100000010001000001000100000000010, 00010000010000010000001000100000100110000000001000011000000010001000100000000100000010001000001000000100000010, 00010000010000000000101000010000100110000010000000011000000010001000100000000100000010001000001000100000000100, 00010000001000010000001000010000100110000001000000011000000010001000100000000100000010001000001000000100000010, 00010000010000000000101000010000100110000000001000010100000010010000100000000100000010001000001000000100000100, 01000000010000000000101000010000100110000001000000010100000010010000100000000100000010001000001000100000000100, 00010000010000000100001000100000100110000001000000010100000010010000100000000100000010001000001000100000000100, 00010000001000010000001000010000100110000010000000011000000010001000100000000100000010001000001000100000000100, 00000010001000010000001000010000100110000010000000011000000010001000100000000100000010001000001000000100000010, 10010000010000000100001000000010100101000010000000010001000010001000100000000100000010001000001000000100001000, 10010000001000010000001000000010100101000010000000010001000010001000100000000100000010001000001000100000001000, 00000010010000000000101000100000100110000001000000011000000010001000100000000100000010001000001000100000000100, 01000001000010000000010000000100101010000000001000100001000010001000100000000100000010001001000000000100010000, 00000010001000010000001000100000100110000001000000011000000010001000100000000100000010001000001000000100000010, 00010000001000000000101000010000100110000010000000011000000010001000100000000100000010001000001000100000000010, 00010000010000000100001000100000100110000000000010010100000010010000100000000100000010001000001000100000000001, 00000101000010000000010000000100100101000010000000010001000010001000100000000100000010001000001000000100001000, 00000010010000000000101000100000100110000010000000011000000010001000100000000100000010001000001000000100000100, 00000010001000000000101000010000100110100000000000011000000010001000100000000100000010001000001000000100000100, 00000010010000000000101000010000100110100000000000011000000010001000100000000100000010001000001000000100000010, 00000010010000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000100.1, 01000000001000000100010000000100101010000010000000100001000010001000100000000100000010001001000000100000010000, 00010000001000010000001000010000100110000000001000011000000010001000100000000100000010001000001000100000000100, 01000000010000000000101000100000100110000001000000010100000010010000100000000100000010001000001000000100000100, 00010000010000000000101000100000100110000001000000011000000010001000100000000100000010001000001000100000000010, 00010001000010000000010000000100100101000000000010010001000010001000100000000100000010001000001000000100001000, 01000001000000000000101000010000101001000000000010100000100010001000100000000100000010001000001000000100001000, 00000010010000010000001000010000100110100000000000011000000010001000100000000100000010001000001000000100000100, 01000001000000000000101000010000101001000001000000100000100010001000100000000100000010001000001000000100001000, 00010000010000000100001000100000100110000000000010010100000010010000100000000100000010001000001000100000000100, 00000010001000000000101000100000100110000010000000011000000010001000100000000100000010001000001000100000000100, 01000000001000000000101000010000101001000000000010100000100010001000100000000100000010001000001000000100001000, 00010000001000010000001000010000101001000000001000100000100010001000100000000100000010001000001100000000001000, 01000000010000000100001000010000100110000000000010010100000010010000100000000100000010001000001000000100000001, 10010000010000000100001000000010100101000001000000010001000010001000100000000100000010001000001000000100001000, 01000000010000000100001000100000100110000000001000010100000010010000100000000100000010001000001000000100000001, 00010000001000000100010000000100101010000010000000100001010000001000100000000100000010001001000000000100000100, 10010000010000010000001000000010100101000001000000010001000010001000100000000100000010001000001000100000000100, 01000001000010000000010000000100100101000000001000010001000010001000100000000100000010001000001000000100000001, 00010001000010000000010000000100101010000000001000100001000010001000100000000100000010001001000000000100000100, 00010000010000000000101000010000100110000001000000010100000010010000100000000100000010001000001000100000000100, 00010000001000000100010000000100101010000010000000100001000010001000100000000100000010001001000000100000000100, 00000010001000010000001000100000100110000001000000011000000010001000100000000100000010001000001000100000000100, 00010000001000010000001000010000100110000000001000011000000010001000100000000100000010001000001000000100000100, 01000000010000000100001000010000100110000001000000010100000010010000100000000100000010001000001000100000000001, 00000101000000000100010000000100100101000000001000010001000010001000100000000100000010001000001000000100001000, 00010001000000000100010000000100100101000000001000010001000010001000100000000100000010001000001000000100000001, 00000010001000010000001000010000100110000010000000011000000010001000100000000100000010001000001000100000000100, 00010000010000000000101000100000100110100000000000011000000010001000100000000100000010001000001000100000000100, 00010000010000000000101000010000100110100000000000011000000010001000100000000100000010001000001000100000000010, 00010000001000000100010000000100101010000000001000100001000010001000100000000100000010001001000000000100010000, 00010000001000010000001000100000100110100000000000011000000010001000100000000100000010001000001000000100000100, 01000000010000000100001000010000100110000000000010010100000010010000100000000100000010001000001000000100000100, 00010000001000000000101000100000100110000000001000011000000010001000100000000100000010001000001000100000000010, 00000010001000010000001000100000100110100000000000011000000010001000100000000100000010001000001000000100000100, 00010000010000010000001000100000100110100000000000011000000010001000100000000100000010001000001000100000000100, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 8125 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/encodedShroomsV2.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0703b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing datasets, filling missing values with zeroes\n",
    "train_size = 5700\n",
    "X = np.empty((train_size, 109), dtype=int)\n",
    "y = []\n",
    "X_test = np.empty((8124-train_size, 109), dtype=int)\n",
    "y_test = []\n",
    "j = 0\n",
    "for column in df:\n",
    "    if j < train_size:\n",
    "        if len(df[column].name) == 110:\n",
    "            X_row = []\n",
    "            if df[column].name[0] == '1':\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "        \n",
    "            for i in range(110):\n",
    "                if i > 0:\n",
    "                    if df[column].name[i] == '1':\n",
    "                        X_row.append(1)\n",
    "                    else:\n",
    "                        X_row.append(0)\n",
    "            X[j] = X_row\n",
    "        if len(df[column].name) == 112:\n",
    "            X_row = []\n",
    "            if df[column].name[0] == '1':\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "        \n",
    "            for i in range(110):\n",
    "                if i > 0:\n",
    "                    if df[column].name[i] == '1':\n",
    "                        X_row.append(1)\n",
    "                    else:\n",
    "                        X_row.append(0)\n",
    "            X[j] = X_row\n",
    "    else:\n",
    "        if len(df[column].name) == 110:\n",
    "            X_row = []\n",
    "            if df[column].name[0] == '1':\n",
    "                y_test.append(1)\n",
    "            else:\n",
    "                y_test.append(0)\n",
    "        \n",
    "            for i in range(110):\n",
    "                if i > 0:\n",
    "                    if df[column].name[i] == '1':\n",
    "                        X_row.append(1)\n",
    "                    else:\n",
    "                        X_row.append(0)\n",
    "            X_test[j-train_size] = X_row\n",
    "        if len(df[column].name) == 112:\n",
    "            X_row = []\n",
    "            if df[column].name[0] == '1':\n",
    "                y_test.append(1)\n",
    "            else:\n",
    "                y_test.append(0)\n",
    "        \n",
    "            for i in range(110):\n",
    "                if i > 0:\n",
    "                    if df[column].name[i] == '1':\n",
    "                        X_row.append(1)\n",
    "                    else:\n",
    "                        X_row.append(0)\n",
    "            X_test[j-train_size] = X_row\n",
    "    j = j+1\n",
    "        \n",
    "y = np.array(y)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e343bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81500af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf493de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.\n",
    "        \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the sigmoid of each value of z (z can be a matrix, vector or scalar).\n",
    "    \"\"\"\n",
    "    # convert input to a numpy array\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # =============================================================\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51699675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g( 0 ) =  0.5\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation of sigmoid function here\n",
    "z = 0\n",
    "g = sigmoid(z)\n",
    "\n",
    "print('g(', z, ') = ', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad031cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = (X.shape)\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497298e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    \"\"\"\n",
    "    Compute cost and gradient for logistic regression. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        The parameters for logistic regression. This a vector\n",
    "        of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1) where m is the total number\n",
    "        of data points and n is the number of features. We assume the \n",
    "        intercept has already been added to the input.\n",
    "    \n",
    "    y : arra_like\n",
    "        Labels for the input. This is a vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function. \n",
    "    \n",
    "    grad : array_like\n",
    "        A vector of shape (n+1, ) which is the gradient of the cost\n",
    "        function with respect to theta, at the current values of theta.\n",
    "        \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. You should set J to \n",
    "    the cost. Compute the partial derivatives and set grad to the partial\n",
    "    derivatives of the cost w.r.t. each parameter in theta.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d8ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros): 0.693\n",
      "Expected cost (approx): 0.693\n",
      "\n",
      "Gradient at initial theta (zeros):\n",
      "\t[0.1323, 0.0561, -0.0002]\n"
     ]
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(n+1)\n",
    "\n",
    "cost, grad = costFunction(initial_theta, X, y)\n",
    "\n",
    "print('Cost at initial theta (zeros): {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.693\\n')\n",
    "\n",
    "print('Gradient at initial theta (zeros):')\n",
    "print('\\t[{:.4f}, {:.4f}, {:.4f}]'.format(*grad))\n",
    "\n",
    "# Compute and display cost and gradient with non-zero theta\n",
    "#test_theta = np.array([-24, 0.2, 0.2])\n",
    "#cost, grad = costFunction(test_theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fd0785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.000\n",
      "Expected cost (approx): 0.203\n",
      "\n",
      "theta:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\AppData\\Local\\Temp\\ipykernel_21044\\1102138006.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.26726649, -0.49165445,  1.08978153, -0.24105235, -0.71512327,\n",
       "       -1.25025101,  1.3024348 , -2.1054249 ,  1.55358471,  0.22170961,\n",
       "        0.07794947, -2.03090268,  0.71904091, -0.98064707, -0.96130752,\n",
       "        1.88824978, -0.93476616, -0.51929348,  1.42515663,  1.52751135,\n",
       "       -0.38935278, -0.13906157, -0.31870062,  5.7497105 ,  5.15691811,\n",
       "        0.        , -6.11296616, -6.11296593,  1.49237288, -7.64978025,\n",
       "        5.62935533,  1.70722951, -0.26726649,  0.        , -2.72487941,\n",
       "        2.80230331, -3.6851398 ,  3.2964851 , -0.12160499, -0.1474192 ,\n",
       "        1.29740058,  0.        , -0.80385717, -0.06877725, -0.41919668,\n",
       "       -1.61089769, -1.03665186,  3.47344315, -0.87007628,  0.        ,\n",
       "       -2.13565953,  1.81302292, -3.46591331, -2.63909773,  0.21298448,\n",
       "        0.18531526,  5.04524541, -2.6192886 ,  5.70181176,  0.        ,\n",
       "       -3.19135017, -2.50404763,  1.66735639,  1.71108334, -1.61513882,\n",
       "        0.        , -0.8747143 ,  0.        ,  0.72369205, -1.33849382,\n",
       "        0.29129684,  0.28898974,  0.70697271,  0.        ,  0.        ,\n",
       "       -0.86644773,  0.        ,  1.10655648, -1.37736603, -1.57854069,\n",
       "        0.28170311,  0.82849816,  1.41332113,  0.        , -0.26726649,\n",
       "        0.        ,  0.        ,  1.08521725, -0.80088844,  0.        ,\n",
       "       -3.78513622, -1.44005354,  0.9030146 ,  0.        ,  3.48326274,\n",
       "       -3.71270573,  0.        ,  4.96907595, -3.12422208,  3.4545988 ,\n",
       "        1.6506839 , -3.59028386,  0.        ,  0.        ,  0.56566624,\n",
       "       -0.32908273,  0.86424268,  1.51737676, -0.7055312 , -2.17588862])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 400}\n",
    "\n",
    "# see documention for scipy's optimize.minimize  for description about\n",
    "# the different parameters\n",
    "# The function returns an object `OptimizeResult`\n",
    "# We use truncated Newton algorithm for optimization which is \n",
    "# equivalent to MATLAB's fminunc\n",
    "# See https://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_theta,\n",
    "                        (X, y),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# the fun property of `OptimizeResult` object returns\n",
    "# the value of costFunction at optimized theta\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized theta is in the x property\n",
    "theta = res.x\n",
    "\n",
    "# Print theta to screen\n",
    "print('Cost at theta found by optimize.minimize: {:.3f}'.format(cost))\n",
    "print('Expected cost (approx): 0.203\\n');\n",
    "\n",
    "print('theta:')\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38021693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression.\n",
    "    Computes the predictions for X using a threshold at 0.5 \n",
    "    (i.e., if sigmoid(theta.T*x) >= 0.5, predict 1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parameters for logistic regression. A vecotor of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The data to use for computing predictions. The rows is the number \n",
    "        of points to compute predictions, and columns is the number of\n",
    "        features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p : array_like\n",
    "        Predictions and 0 or 1 for each row in X. \n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Complete the following code to make predictions using your learned \n",
    "    logistic regression parameters.You should set p to a vector of 0's and 1's    \n",
    "    \"\"\"\n",
    "    m = X.shape[0] # Number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    p = np.round(sigmoid(X.dot(theta.T)))\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc742c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we predict an admission probability of 0.000\n",
      "Train Accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "test = np.column_stack((y_test, X_test))\n",
    "#  Predict probability for a student with score 45 on exam 1 \n",
    "#  and score 85 on exam 2 \n",
    "prob = sigmoid(np.dot(list(test[4]), theta))\n",
    "print('we predict an admission probability of {:.3f}'.format(prob))\n",
    "\n",
    "# Compute accuracy on our training set\n",
    "p = predict(theta, X)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce55753e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889792966021409"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "tot_prob = 0\n",
    "for i in range(len(test)):\n",
    "    prob = sigmoid(np.dot(list(test[i]), theta))\n",
    "    if round(prob, 0) == 0:\n",
    "        tot_prob = tot_prob + 1-prob\n",
    "    else:\n",
    "        tot_prob = tot_prob + prob\n",
    "    if round(prob, 0) == y_test[i]:\n",
    "        score = score + 1\n",
    "tot_prob = tot_prob/len(test)\n",
    "tot_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91fcaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9257425742574258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078bd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
